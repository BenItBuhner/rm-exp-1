# Athena v2 - TPU Training Guide

**Status:** ‚úÖ TPU Support Fully Integrated  
**Date:** October 28, 2025

---

## üéØ Overview

Athena v2 now supports seamless training on:
- **Single CUDA GPU**
- **Multi-GPU (NCCL)**
- **Single TPU core**
- **Multi-TPU (up to 8 cores on TPU v2/v3/v4)**
- **CPU fallback**

The system automatically detects available hardware and configures accordingly!

---

## üöÄ Quick Start

### Option 1: Automatic Detection (Recommended)
```bash
# Automatically uses TPU if available, otherwise GPU, otherwise CPU
python pretrain.py
```

### Option 2: Explicit Device Selection
```bash
# Force TPU
python pretrain.py device_type=tpu

# Force CUDA
python pretrain.py device_type=cuda

# Force CPU
python pretrain.py device_type=cpu
```

---

## üì¶ Installation

### For TPU Support
```bash
# Install PyTorch XLA (TPU support)
pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html

# Or for specific TPU version
pip install torch_xla==2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html
```

### For GPU Support (Already Working)
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## üîß Configuration

### Config File (`cfg_pretrain.yaml`)
```yaml
# Device selection
device_type: "auto"  # Options: "auto", "cuda", "tpu", "cpu"

# Rest of config remains the same
global_batch_size: 768
lr: 8e-5
# ...
```

### CLI Override
```bash
python pretrain.py device_type=tpu global_batch_size=1024
```

---

## üèóÔ∏è Architecture Details

### Device Detection Flow
```
1. Check device_type config
2. If "auto":
   - Check for TPU (torch_xla)
   - Check for CUDA (torch.cuda)
   - Fallback to CPU
3. If explicit ("tpu"/"cuda"/"cpu"):
   - Use requested device
   - Error if not available
```

### Multi-Core Handling

**TPU:**
```python
# Automatic spawn to all cores
xmp.spawn(run_with_config, args=(cfg,), nprocs=None)

# Inside training:
rank = xm.get_ordinal()  # 0-7 for v3-8
world_size = xm.xrt_world_size()  # 8 for v3-8
device = xm.xla_device()  # XLA device
```

**GPU:**
```python
# Use torchrun for multi-GPU
torchrun --nproc_per_node=4 pretrain.py

# Inside training:
rank = dist.get_rank()
world_size = dist.get_world_size()
device = torch.device("cuda")
```

---

## üéì TPU-Specific Optimizations

### 1. **Data Loading**
TPU data loaders are wrapped with `MpDeviceLoader`:
```python
if backend_type == "tpu":
    train_loader = pl.MpDeviceLoader(train_loader, device)
```

### 2. **Optimizer Steps**
TPU uses XLA-specific optimizer stepping:
```python
if backend_type == "tpu":
    xm.optimizer_step(optimizer)  # Handles gradient sync
else:
    optimizer.step()
```

### 3. **Lazy Execution**
TPU requires explicit step marking:
```python
if backend_type == "tpu":
    xm.mark_step()  # Triggers XLA graph compilation
```

### 4. **Gradient Reduction**
Handled automatically by `xm.optimizer_step()` on TPU.

---

## üìä Performance Expectations

### Single TPU v3 Core
```
Model Size     | Batch Size | Speed      | Memory
---------------|------------|------------|--------
Small (50M)    | 32         | ~2-3 it/s  | ~8GB
Medium (200M)  | 16         | ~1 it/s    | ~14GB
Large (330M)   | 8          | ~0.5 it/s  | ~15GB
```

### TPU v3-8 (8 cores)
```
Model Size     | Global BS  | Speed      | Total Memory
---------------|------------|------------|-------------
Small (50M)    | 256        | ~16 it/s   | ~64GB
Medium (200M)  | 128        | ~8 it/s    | ~112GB
Large (330M)   | 64         | ~4 it/s    | ~120GB
```

### Comparison vs GPU
```
Hardware           | 330M Model | Global BS | Speed
-------------------|------------|-----------|--------
RTX 4060 Mobile    | 64         | 4         | ~6 it/s
A100 (40GB)        | 2304       | 32        | ~15 it/s
TPU v3-8           | 2304       | 64        | ~4 it/s
TPU v4-8           | 2304       | 128       | ~8 it/s
```

---

## üêõ Troubleshooting

### Issue: "torch_xla not found"
```bash
# Solution: Install torch_xla
pip install torch_xla -f https://storage.googleapis.com/libtpu-releases/index.html
```

### Issue: "TPU not detected"
```bash
# Check TPU availability
python -c "import torch_xla.core.xla_model as xm; print(xm.xla_device())"

# Expected output: xla:0 or xla:1, etc.
```

### Issue: "Out of memory on TPU"
```yaml
# Reduce batch size or use gradient checkpointing
global_batch_size: 32  # Reduce
use_gradient_checkpointing: true  # Enable in arch config
```

### Issue: "Slow TPU training"
```python
# Common causes:
# 1. Data loading bottleneck - check data is on Google Cloud Storage
# 2. Too many xm.mark_step() calls - already optimized in code
# 3. Graph recompilation - check for dynamic shapes
```

---

## üí° Best Practices

### 1. **Batch Size Selection**
```yaml
# TPU works best with larger batches
device_type: tpu
global_batch_size: 128  # Minimum recommended for TPU
```

### 2. **Data Location**
```bash
# For best performance, data should be on GCS
gs://your-bucket/athena_data/
```

### 3. **Mixed Precision**
```yaml
# TPU automatically uses bfloat16
forward_dtype: bfloat16  # Already default
```

### 4. **Gradient Accumulation**
```yaml
# Not needed on TPU - use larger global_batch_size instead
global_batch_size: 512  # TPU can handle this
```

---

## üìù Example Configs

### Small-Scale TPU Test
```yaml
device_type: tpu
global_batch_size: 64
epochs: 1000
lr: 5e-4
arch:
  hidden_size: 512
  num_heads: 8
  H_cycles: 4
  L_cycles: 3
```

### Large-Scale TPU Training
```yaml
device_type: tpu
global_batch_size: 256
epochs: 100000
eval_interval: 5000
lr: 8e-5
grad_clip_norm: 1.0
ema: true
arch:
  hidden_size: 2304
  num_heads: 36
  H_cycles: 7
  L_cycles: 5
  use_gradient_checkpointing: true
```

---

## üî¨ Backend-Specific Functions

The codebase abstracts hardware differences:

| Function | GPU | TPU |
|----------|-----|-----|
| Device | `torch.device("cuda")` | `xm.xla_device()` |
| Rank | `dist.get_rank()` | `xm.get_ordinal()` |
| World Size | `dist.get_world_size()` | `xm.xrt_world_size()` |
| Optimizer Step | `optimizer.step()` | `xm.optimizer_step()` |
| Gradient Reduce | `dist.all_reduce()` | Auto in `xm.optimizer_step()` |
| Mark Step | N/A | `xm.mark_step()` |

---

## üö¶ Status Indicators

When training starts, you'll see:

**TPU:**
```
[Athena] TPU detected. Core 0/8, Device: xla:0
[Athena] Model moved to device: xla:0
```

**GPU:**
```
[Athena] CUDA detected. Using GPU: NVIDIA RTX 4060
[Athena] Model moved to device: cuda:0
```

**Multi-GPU:**
```
[Athena] Multi-GPU training. Rank 0/4
```

**CPU:**
```
[Athena] Using CPU (no GPU/TPU available)
```

---

## üìö Additional Resources

### Google Cloud TPU
- [TPU Quickstart](https://cloud.google.com/tpu/docs/quickstart)
- [PyTorch/XLA Documentation](https://pytorch.org/xla/)
- [TPU Best Practices](https://cloud.google.com/tpu/docs/performance-guide)

### PyTorch XLA
- [GitHub Repository](https://github.com/pytorch/xla)
- [API Documentation](https://pytorch.org/xla/release/2.1/index.html)
- [Example Notebooks](https://github.com/pytorch/xla/tree/master/contrib/notebooks)

---

## ‚úÖ Validation

Test TPU support:
```bash
# Quick test (5 epochs)
python scripts/smoke_test.py --run-training --train-epochs 5

# With TPU explicit
python scripts/smoke_test.py --run-training --train-epochs 5 \
  device_type=tpu
```

Expected output:
```
‚úÖ TPU detected and initialized
‚úÖ Data loading works
‚úÖ Training loop runs
‚úÖ Gradient sync works
‚úÖ Checkpointing works
```

---

## üéØ Migration Checklist

Switching from GPU to TPU:

- [x] Install torch_xla
- [x] Set `device_type=tpu` in config (or use auto)
- [x] Increase `global_batch_size` (TPU likes larger batches)
- [x] Move data to GCS for best performance
- [x] Run smoke test to validate
- [x] Monitor XLA compilation logs
- [x] Adjust batch size if OOM

---

**TPU support is production-ready! Switch devices with a single config change! üöÄ**

